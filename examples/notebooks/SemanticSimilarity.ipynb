{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c02b0509",
   "metadata": {},
   "source": [
    "# Semantic Similarity Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac35f8",
   "metadata": {},
   "source": [
    "## Setup imports and API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edba05a",
   "metadata": {},
   "source": [
    "First, we'll need to set our API keys. If we are in DEBUG mode, we don't need to use real OpenAI or Hegel AI API keys, so for now we'll set them to empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed4e635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DEBUG']=\"1\"\n",
    "os.environ['HEGELAI_API_KEY'] = \"\"\n",
    "os.environ['OPENAI_API_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3934db",
   "metadata": {},
   "source": [
    "Then we'll import the relevant `prompttools` modules to setup our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0841dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "from prompttools.harness.prompt_template_harness import (\n",
    "    PromptTemplateExperimentationHarness,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b106a04",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43545ff",
   "metadata": {},
   "source": [
    "Next, we create our test inputs. For this example, we'll use a prompt template, which uses [jinja](https://jinja.palletsprojects.com/en/3.1.x/) for templating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbab6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templates = [\"Answer the following question: {{input}}\", \"Respond the following query: {{input}}\"]\n",
    "user_inputs = [{\"input\": \"Who was the first president?\"}, {\"input\": \"Who was the first president of India?\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d152fdf",
   "metadata": {},
   "source": [
    "Now we can define an experimentation harness for our inputs and model. We could also pass model arguments if, for example, we wanted to change the model temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3086e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "harness = PromptTemplateExperimentationHarness(\"text-davinci-003\", prompt_templates, user_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f5463a",
   "metadata": {},
   "source": [
    "We can then run the experiment to get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84304957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>response(s)</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Answer the following question: Who was the first president?</td>\n",
       "      <td>[\\n\\nThe Los Angeles Dodgers won the World Series in 2020]</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Answer the following question: Who was the first president of India?</td>\n",
       "      <td>[\\n\\nThe Los Angeles Dodgers won the World Series in 2020]</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Respond the following query: Who was the first president?</td>\n",
       "      <td>[\\n\\nThe Los Angeles Dodgers won the World Series in 2020]</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Respond the following query: Who was the first president of India?</td>\n",
       "      <td>[\\n\\nThe Los Angeles Dodgers won the World Series in 2020]</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               messages   \n",
       "0  Answer the following question: Who was the first president?           \\\n",
       "1  Answer the following question: Who was the first president of India?   \n",
       "2  Respond the following query: Who was the first president?              \n",
       "3  Respond the following query: Who was the first president of India?     \n",
       "\n",
       "                                                  response(s)   latency  \n",
       "0  [\\n\\nThe Los Angeles Dodgers won the World Series in 2020]  0.000004  \n",
       "1  [\\n\\nThe Los Angeles Dodgers won the World Series in 2020]  0.000002  \n",
       "2  [\\n\\nThe Los Angeles Dodgers won the World Series in 2020]  0.000002  \n",
       "3  [\\n\\nThe Los Angeles Dodgers won the World Series in 2020]  0.000001  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "harness.prepare()\n",
    "harness.run()\n",
    "harness.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35caa9a",
   "metadata": {},
   "source": [
    "You can use the `pivot` keyword argument to view results by the template and inputs that created them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc2f1bde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prompt_template</th>\n",
       "      <th>Answer the following question: {{input}}</th>\n",
       "      <th>Respond the following query: {{input}}</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_input</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{'input': 'Who was the first president of India?'}</th>\n",
       "      <td>[\\n\\nThe Los Angeles Dodgers won the World Series in 2020]</td>\n",
       "      <td>[\\n\\nThe Los Angeles Dodgers won the World Series in 2020]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'input': 'Who was the first president?'}</th>\n",
       "      <td>[\\n\\nThe Los Angeles Dodgers won the World Series in 2020]</td>\n",
       "      <td>[\\n\\nThe Los Angeles Dodgers won the World Series in 2020]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prompt_template                                                       Answer the following question: {{input}}   \n",
       "user_input                                                                                                       \n",
       "{'input': 'Who was the first president of India?'}  [\\n\\nThe Los Angeles Dodgers won the World Series in 2020]  \\\n",
       "{'input': 'Who was the first president?'}           [\\n\\nThe Los Angeles Dodgers won the World Series in 2020]   \n",
       "\n",
       "prompt_template                                                         Respond the following query: {{input}}  \n",
       "user_input                                                                                                      \n",
       "{'input': 'Who was the first president of India?'}  [\\n\\nThe Los Angeles Dodgers won the World Series in 2020]  \n",
       "{'input': 'Who was the first president?'}           [\\n\\nThe Los Angeles Dodgers won the World Series in 2020]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "harness.visualize(pivot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c13eb",
   "metadata": {},
   "source": [
    "## Evaluate the model response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb8023",
   "metadata": {},
   "source": [
    "To evaluate the results, we'll define an eval function. Since we are prompting the model to echo our input, we can use semantic distance to check if the model's response is similar to the user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63de3014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompttools.utils import similarity\n",
    "\n",
    "\n",
    "EXPECTED = {\"Who was the first president?\": \"George Washington\",\n",
    "            \"Who was the first president of India?\": \"Rajendra Prasad\"}\n",
    "\n",
    "def extract_responses(output) -> str:\n",
    "    return [choice[\"text\"] for choice in output[\"choices\"]]\n",
    "\n",
    "\n",
    "def measure_similarity(\n",
    "    input_pair: Tuple[str, Dict[str, str]], results: Dict, metadata: Dict\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    A simple test that checks semantic similarity between the user input\n",
    "    and the model's text responses.\n",
    "    \"\"\"\n",
    "    distances = [\n",
    "        similarity.compute(EXPECTED[input_pair[1][\"input\"]], response)\n",
    "        for response in extract_responses(results)\n",
    "    ]\n",
    "    return min(distances)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a277d94",
   "metadata": {},
   "source": [
    "Let's test our similarity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94f8701d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-05 09:19:54,457] INFO in posthog: Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
      "[2023-07-05 09:19:54,471] INFO in ctypes: Successfully imported ClickHouse Connect C data optimizations\n",
      "[2023-07-05 09:19:54,472] INFO in ctypes: Successfully import ClickHouse Connect C/Numpy optimizations\n",
      "[2023-07-05 09:19:54,478] INFO in json_impl: Using python library for writing JSON byte strings\n",
      "[2023-07-05 09:19:54,558] WARNING in Collection: No embedding_function provided, using default embedding function: DefaultEmbeddingFunction https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
      "[2023-07-05 09:19:54,844] WARNING in Collection: No embedding_function provided, using default embedding function: DefaultEmbeddingFunction https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8258005976676941"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_similarity((prompt_templates[0], user_inputs[0]), {\"choices\": [{\"text\": \"This is a test\"}, {\"text\": \"This is a text\"}]}, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d6065",
   "metadata": {},
   "source": [
    "Finally, we can evaluate and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "233f25a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-05 09:19:55,087] WARNING in Collection: No embedding_function provided, using default embedding function: DefaultEmbeddingFunction https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
      "[2023-07-05 09:19:55,320] WARNING in Collection: No embedding_function provided, using default embedding function: DefaultEmbeddingFunction https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
      "[2023-07-05 09:19:55,552] WARNING in Collection: No embedding_function provided, using default embedding function: DefaultEmbeddingFunction https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
      "[2023-07-05 09:19:55,787] WARNING in Collection: No embedding_function provided, using default embedding function: DefaultEmbeddingFunction https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>response(s)</th>\n",
       "      <th>latency</th>\n",
       "      <th>similar_to_expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Answer the following question: Who was the first president?</td>\n",
       "      <td>[\\n\\nThe Los Angeles Dodgers won the World Series in 2020]</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.965657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Answer the following question: Who was the first president of India?</td>\n",
       "      <td>[\\n\\nThe Los Angeles Dodgers won the World Series in 2020]</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.021784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Respond the following query: Who was the first president?</td>\n",
       "      <td>[\\n\\nThe Los Angeles Dodgers won the World Series in 2020]</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.965657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Respond the following query: Who was the first president of India?</td>\n",
       "      <td>[\\n\\nThe Los Angeles Dodgers won the World Series in 2020]</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.021784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               messages   \n",
       "0  Answer the following question: Who was the first president?           \\\n",
       "1  Answer the following question: Who was the first president of India?   \n",
       "2  Respond the following query: Who was the first president?              \n",
       "3  Respond the following query: Who was the first president of India?     \n",
       "\n",
       "                                                  response(s)   latency   \n",
       "0  [\\n\\nThe Los Angeles Dodgers won the World Series in 2020]  0.000004  \\\n",
       "1  [\\n\\nThe Los Angeles Dodgers won the World Series in 2020]  0.000002   \n",
       "2  [\\n\\nThe Los Angeles Dodgers won the World Series in 2020]  0.000002   \n",
       "3  [\\n\\nThe Los Angeles Dodgers won the World Series in 2020]  0.000001   \n",
       "\n",
       "   similar_to_expected  \n",
       "0  0.965657             \n",
       "1  1.021784             \n",
       "2  0.965657             \n",
       "3  1.021784             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "harness.evaluate(\"similar_to_expected\", measure_similarity)\n",
    "harness.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6173e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c36bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
