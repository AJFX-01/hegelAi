{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7dea195",
   "metadata": {},
   "source": [
    "# Auto-Evaluation Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a80e19b",
   "metadata": {},
   "source": [
    "## Setup imports and API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f1521a",
   "metadata": {},
   "source": [
    "First, we'll need to set our API keys. If we are in DEBUG mode, we don't need to use real OpenAI or Hegel AI API keys, so for now we'll set them to empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb85245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HEGELAI_API_KEY'] = \"\"\n",
    "os.environ['OPENAI_API_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ac0bb",
   "metadata": {},
   "source": [
    "Then we'll import the relevant `prompttools` modules to setup our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3859e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from prompttools.harness.prompt_template_harness import (\n",
    "    PromptTemplateExperimentationHarness,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcfbb5b",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f517570f",
   "metadata": {},
   "source": [
    "Next, we create our test inputs. For this example, we'll use a prompt template, which uses [jinja](https://jinja.palletsprojects.com/en/3.1.x/) for templating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29408faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templates = [\"Echo the following input: {{input}}\", \"Repeat the following input: {{input}}\"]\n",
    "user_inputs = [{\"input\": \"This is a test\"}, {\"input\": \"This is not a test\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a1777",
   "metadata": {},
   "source": [
    "Now we can define an experimentation harness for our inputs and model. We could also pass model arguments if, for example, we wanted to change the model temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69159622",
   "metadata": {},
   "outputs": [],
   "source": [
    "harness = PromptTemplateExperimentationHarness(\"text-davinci-003\", prompt_templates, user_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af04bd60",
   "metadata": {},
   "source": [
    "We can then run the experiment to get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744ab156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>response(s)</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Echo the following input: This is a test</td>\n",
       "      <td>[\\n\\nThis is a test]</td>\n",
       "      <td>2.608490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Echo the following input: This is not a test</td>\n",
       "      <td>[\\n\\nThis is not a test]</td>\n",
       "      <td>2.105207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Repeat the following input: This is a test</td>\n",
       "      <td>[\\n\\nThis is a test]</td>\n",
       "      <td>0.510293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Repeat the following input: This is not a test</td>\n",
       "      <td>[\\n\\nThis is not a test]</td>\n",
       "      <td>1.843766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         messages               response(s)   \n",
       "0  Echo the following input: This is a test        [\\n\\nThis is a test]      \\\n",
       "1  Echo the following input: This is not a test    [\\n\\nThis is not a test]   \n",
       "2  Repeat the following input: This is a test      [\\n\\nThis is a test]       \n",
       "3  Repeat the following input: This is not a test  [\\n\\nThis is not a test]   \n",
       "\n",
       "    latency  \n",
       "0  2.608490  \n",
       "1  2.105207  \n",
       "2  0.510293  \n",
       "3  1.843766  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "harness.prepare()\n",
    "harness.run()\n",
    "harness.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a7391",
   "metadata": {},
   "source": [
    "You can use the `pivot` keyword argument to view results by the template and inputs that created them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb779595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prompt_template</th>\n",
       "      <th>Echo the following input: {{input}}</th>\n",
       "      <th>Repeat the following input: {{input}}</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_input</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{'input': 'This is a test'}</th>\n",
       "      <td>[\\n\\nThis is a test]</td>\n",
       "      <td>[\\n\\nThis is a test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'input': 'This is not a test'}</th>\n",
       "      <td>[\\n\\nThis is not a test]</td>\n",
       "      <td>[\\n\\nThis is not a test]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prompt_template                 Echo the following input: {{input}}   \n",
       "user_input                                                            \n",
       "{'input': 'This is a test'}      [\\n\\nThis is a test]                \\\n",
       "{'input': 'This is not a test'}  [\\n\\nThis is not a test]             \n",
       "\n",
       "prompt_template                 Repeat the following input: {{input}}  \n",
       "user_input                                                             \n",
       "{'input': 'This is a test'}      [\\n\\nThis is a test]                  \n",
       "{'input': 'This is not a test'}  [\\n\\nThis is not a test]              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "harness.visualize(pivot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd320e",
   "metadata": {},
   "source": [
    "## Auto-Evaluate the model response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36767bd",
   "metadata": {},
   "source": [
    "To evaluate the model response, we can define an eval method that passes the input and response into another LLM to get feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fe03c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import jinja2\n",
    "\n",
    "ECHO_EVALUATION_TEMPLATE=\"\"\"\n",
    "Determine whether or not the response is following directions.\n",
    "Your answer should either be \"RIGHT\" if the response follows directions,\n",
    "or \"WRONG\" if the model is not following directions.\n",
    "\n",
    "Write your answer here:\n",
    "PROMPT: {{prompt}}\n",
    "RESPONSE: {{response}}\n",
    "ANSWER: \n",
    "\"\"\"\n",
    "\n",
    "def extract_responses(output) -> str:\n",
    "    return [choice[\"text\"] for choice in output[\"choices\"]]\n",
    "\n",
    "def auto_eval(prompt: str, results: Dict, metadata: Dict) -> float:\n",
    "    environment = jinja2.Environment()\n",
    "    template = environment.from_string(ECHO_EVALUATION_TEMPLATE)\n",
    "    responses = extract_responses(results)\n",
    "    prompts = [template.render({\"prompt\": prompt, \n",
    "                                \"response\": response}) for response in responses]\n",
    "    evals = [openai.Completion.create(model=\"text-davinci-003\",\n",
    "                                      prompt=prompt) for prompt in prompts]\n",
    "    return float(sum([1 if 'RIGHT' in e['choices'][0]['text'] else 0 for e in evals]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3008b09e",
   "metadata": {},
   "source": [
    "Finally, we can evaluate and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4633f802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<OpenAIObject text_completion id=cmpl-7Yl3SC4jCsVc2mJMNZmUEomK8BKZa at 0x11e656e10> JSON: {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" RIGHT\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1688518386,\n",
      "  \"id\": \"cmpl-7Yl3SC4jCsVc2mJMNZmUEomK8BKZa\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1,\n",
      "    \"prompt_tokens\": 82,\n",
      "    \"total_tokens\": 83\n",
      "  }\n",
      "}]\n",
      "[<OpenAIObject text_completion id=cmpl-7Yl3T3VGQLUlP50Pt3blH1tTCI0O3 at 0x11e6575f0> JSON: {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" RIGHT\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1688518387,\n",
      "  \"id\": \"cmpl-7Yl3T3VGQLUlP50Pt3blH1tTCI0O3\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1,\n",
      "    \"prompt_tokens\": 84,\n",
      "    \"total_tokens\": 85\n",
      "  }\n",
      "}]\n",
      "[<OpenAIObject text_completion id=cmpl-7Yl3UaVALivISZx7dqcpZrkXV0ug8 at 0x11e6575f0> JSON: {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" RIGHT\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1688518388,\n",
      "  \"id\": \"cmpl-7Yl3UaVALivISZx7dqcpZrkXV0ug8\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1,\n",
      "    \"prompt_tokens\": 82,\n",
      "    \"total_tokens\": 83\n",
      "  }\n",
      "}]\n",
      "[<OpenAIObject text_completion id=cmpl-7Yl3VNLQwzHxcKDeYZ0VQ3fb72LiM at 0x11e656930> JSON: {\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" RIGHT\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1688518389,\n",
      "  \"id\": \"cmpl-7Yl3VNLQwzHxcKDeYZ0VQ3fb72LiM\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1,\n",
      "    \"prompt_tokens\": 84,\n",
      "    \"total_tokens\": 85\n",
      "  }\n",
      "}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>response(s)</th>\n",
       "      <th>latency</th>\n",
       "      <th>followed_directions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Echo the following input: This is a test</td>\n",
       "      <td>[\\n\\nThis is a test]</td>\n",
       "      <td>2.608490</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Echo the following input: This is not a test</td>\n",
       "      <td>[\\n\\nThis is not a test]</td>\n",
       "      <td>2.105207</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Repeat the following input: This is a test</td>\n",
       "      <td>[\\n\\nThis is a test]</td>\n",
       "      <td>0.510293</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Repeat the following input: This is not a test</td>\n",
       "      <td>[\\n\\nThis is not a test]</td>\n",
       "      <td>1.843766</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         messages               response(s)   \n",
       "0  Echo the following input: This is a test        [\\n\\nThis is a test]      \\\n",
       "1  Echo the following input: This is not a test    [\\n\\nThis is not a test]   \n",
       "2  Repeat the following input: This is a test      [\\n\\nThis is a test]       \n",
       "3  Repeat the following input: This is not a test  [\\n\\nThis is not a test]   \n",
       "\n",
       "    latency  followed_directions  \n",
       "0  2.608490  1.0                  \n",
       "1  2.105207  1.0                  \n",
       "2  0.510293  1.0                  \n",
       "3  1.843766  1.0                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "harness.evaluate(\"followed_directions\", auto_eval)\n",
    "harness.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d65f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
