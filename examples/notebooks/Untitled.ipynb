{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a13ddc8",
   "metadata": {},
   "source": [
    "# Open Source vc OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780dc3bf",
   "metadata": {},
   "source": [
    "Wondering how much better Llama 2 is compared to Llama?\n",
    "\n",
    "In this notebook, we'll use auto-evaluation by GPT-4 to measure outputs from both Llama and Llama 2 on a few prompts. To make this example easy to run, we'll be using 7B GGML variants of the Llama models. This should be able to run on a typical laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623f0cfe",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52881369",
   "metadata": {},
   "source": [
    "You can setup prompttools either by installing via `pip` or using `python setup.py develop` in the root of this repo. Either way, you'll need to restart the kernel after the package is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "885dabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet --force-reinstall prompttools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac35f8",
   "metadata": {},
   "source": [
    "## Setup imports and API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edba05a",
   "metadata": {},
   "source": [
    "Next, we'll need to set our API keys. Since we want to use GPT-4 for auto-eval, we need to set that one. We won't be using the Hegel AI API key for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed4e635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DEBUG'] = \"1\"\n",
    "os.environ['HEGELAI_API_KEY'] = \"\"\n",
    "os.environ['OPENAI_API_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f1e47",
   "metadata": {},
   "source": [
    "Then we'll import the relevant `prompttools` modules to setup our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beaa70a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "from prompttools.experiment import LlamaCppExperiment\n",
    "from prompttools.experiment import OpenAIChatExperiment\n",
    "from prompttools.harness.multi_experiment_harness import MultiExperimentHarness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622dea9a",
   "metadata": {},
   "source": [
    "## Run an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3babfe5a",
   "metadata": {},
   "source": [
    "Next, we create our test inputs. We can iterate over models, inputs, and configurations like temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9114cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = ['/Users/stevenkrawczyk/Downloads/llama-2-7b-chat.ggmlv3.q2_K.bin']  # Download from https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main\n",
    "prompts = [\n",
    "    \"\"\"\n",
    "    OBJECTIVE:\n",
    "    You are a sales development representative for a startup called Hegel AI.\n",
    "    Your startup builds developer tools for large language models.\n",
    "    Draft a short sales email, 50 words or less, asking a prospect for 15 minutes\n",
    "    of their time to chat about how they're using large language models.\n",
    "    \n",
    "    RESPONSE:\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    OBJECTIVE:\n",
    "    You are a customer support representative for a startup called Hegel AI.\n",
    "    Answer the following customer question:\n",
    "    Do you offer refunds?\n",
    "    \n",
    "    RESPONSE:\n",
    "    \"\"\"\n",
    "]\n",
    "temperatures = [1.0]\n",
    "call_params = dict(temperature=temperatures)\n",
    "llama_experiment = LlamaCppExperiment(model_paths, prompts, call_params=call_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575032d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['gpt-4-0314', 'gpt-4-0613', 'gpt-4']\n",
    "messages = [[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Who was the first president?\"},\n",
    "]]\n",
    "temperatures = [0.0]\n",
    "\n",
    "openai_experiment = OpenAIChatExperiment(models, messages, temperature=temperatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ef4f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "harness = MultiExperimentHarness([openai_experiment, llama_experiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f22ebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /Users/stevenkrawczyk/Downloads/llama-2-7b-chat.ggmlv3.q2_K.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 10 (mostly Q2_K)\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
      "llama_model_load_internal: mem required  = 4525.65 MB (+ 1026.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  256.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | \n",
      "\n",
      "llama_print_timings:        load time = 11941.03 ms\n",
      "llama_print_timings:      sample time =   106.52 ms /   128 runs   (    0.83 ms per token,  1201.62 tokens per second)\n",
      "llama_print_timings: prompt eval time = 11940.95 ms /    92 tokens (  129.79 ms per token,     7.70 tokens per second)\n",
      "llama_print_timings:        eval time = 16828.11 ms /   127 runs   (  132.50 ms per token,     7.55 tokens per second)\n",
      "llama_print_timings:       total time = 29220.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time = 11941.03 ms\n",
      "llama_print_timings:      sample time =    49.83 ms /    59 runs   (    0.84 ms per token,  1184.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  9876.59 ms /    42 tokens (  235.16 ms per token,     4.25 tokens per second)\n",
      "llama_print_timings:        eval time =  8615.17 ms /    58 runs   (  148.54 ms per token,     6.73 tokens per second)\n",
      "llama_print_timings:       total time = 18704.92 ms\n"
     ]
    }
   ],
   "source": [
    "harness.prepare()\n",
    "harness.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ddbb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompttools.utils import autoeval\n",
    "\n",
    "\n",
    "def extract_responses(output) -> str:\n",
    "    return [choice[\"text\"] for choice in output[\"choices\"]]\n",
    "\n",
    "\n",
    "def use_gpt4(\n",
    "    prompt: str, results: Dict, metadata: Dict\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    A simple test that checks semantic similarity between the user input\n",
    "    and the model's text responses.\n",
    "    \"\"\"\n",
    "    return 0.0\n",
    "#     distances = [\n",
    "#         autoeval.compute(prompt, response)\n",
    "#         for response in extract_responses(results)\n",
    "#     ]\n",
    "#     return min(distances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d6065",
   "metadata": {},
   "source": [
    "Finally, we can evaluate and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e80dfeec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "harness.evaluate(\"auto-evaluation\", use_gpt4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d09c18e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'latency': [5.138979759067297e-06, 3.362016286700964e-06, 2.558052074164152e-06, 29.22151685395511, 18.70563395199133], 'auto-evaluation': [0.0, 0.0, 0.0, 0.0, 0.0]})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model</th>\n",
       "      <th>gpt-4</th>\n",
       "      <th>gpt-4-0314</th>\n",
       "      <th>gpt-4-0613</th>\n",
       "      <th>llama-2-7b-chat.ggmlv3.q2_K.bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\\n    OBJECTIVE:\\n    You are a customer support representative for a startup called Hegel AI.\\n    Answer the following customer question:\\n    Do you offer refunds?\\n    \\n    RESPONSE:\\n</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ Yes, at Hegel AI we understand that sometimes our customers may need to return or cancel their orders. We do indeed offer refunds on certain products. The policy for refunds is available on our website under the \"Returns and Refunds\" section. ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\n    OBJECTIVE:\\n    You are a sales development representative for a startup called Hegel AI.\\n    Your startup builds developer tools for large language models.\\n    Draft a short sales email, 50 words or less, asking a prospect for 15 minutes\\n    of their time to chat about how they're using large language models.\\n    \\n    RESPONSE:\\n</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\\n    Subject: Quick Chat on Large Language Models?\\n    \\n    Hi [Prospect Name],\\n    Hope this finds you well! I'm [Your Name], a sales development \\n     representative from Hegel AI, an innovative startup developing \\n     developer tools for large language models. \\n     We have developed cutting-edge technologies to aid in the \\n     improvement and optimization of these models.\\n     \\n       Our products can enhance the efficiency and quality of your work.\\n        I would love to arrange a brief discussion with you to discuss how ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Who was the first president?</th>\n",
       "      <td>[George Washington]</td>\n",
       "      <td>[George Washington]</td>\n",
       "      <td>[George Washington]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model                                                                                                                                                                                                                                                                                                                                                                      gpt-4   \n",
       "prompt                                                                                                                                                                                                                                                                                                                                                                             \n",
       "\\n    OBJECTIVE:\\n    You are a customer support representative for a startup called Hegel AI.\\n    Answer the following customer question:\\n    Do you offer refunds?\\n    \\n    RESPONSE:\\n                                                                                                                                                                NaN                  \\\n",
       "\\n    OBJECTIVE:\\n    You are a sales development representative for a startup called Hegel AI.\\n    Your startup builds developer tools for large language models.\\n    Draft a short sales email, 50 words or less, asking a prospect for 15 minutes\\n    of their time to chat about how they're using large language models.\\n    \\n    RESPONSE:\\n      NaN                   \n",
       "Who was the first president?                                                                                                                                                                                                                                                                                                                                 [George Washington]   \n",
       "\n",
       "model                                                                                                                                                                                                                                                                                                                                                                 gpt-4-0314   \n",
       "prompt                                                                                                                                                                                                                                                                                                                                                                             \n",
       "\\n    OBJECTIVE:\\n    You are a customer support representative for a startup called Hegel AI.\\n    Answer the following customer question:\\n    Do you offer refunds?\\n    \\n    RESPONSE:\\n                                                                                                                                                                NaN                  \\\n",
       "\\n    OBJECTIVE:\\n    You are a sales development representative for a startup called Hegel AI.\\n    Your startup builds developer tools for large language models.\\n    Draft a short sales email, 50 words or less, asking a prospect for 15 minutes\\n    of their time to chat about how they're using large language models.\\n    \\n    RESPONSE:\\n      NaN                   \n",
       "Who was the first president?                                                                                                                                                                                                                                                                                                                                 [George Washington]   \n",
       "\n",
       "model                                                                                                                                                                                                                                                                                                                                                                 gpt-4-0613   \n",
       "prompt                                                                                                                                                                                                                                                                                                                                                                             \n",
       "\\n    OBJECTIVE:\\n    You are a customer support representative for a startup called Hegel AI.\\n    Answer the following customer question:\\n    Do you offer refunds?\\n    \\n    RESPONSE:\\n                                                                                                                                                                NaN                  \\\n",
       "\\n    OBJECTIVE:\\n    You are a sales development representative for a startup called Hegel AI.\\n    Your startup builds developer tools for large language models.\\n    Draft a short sales email, 50 words or less, asking a prospect for 15 minutes\\n    of their time to chat about how they're using large language models.\\n    \\n    RESPONSE:\\n      NaN                   \n",
       "Who was the first president?                                                                                                                                                                                                                                                                                                                                 [George Washington]   \n",
       "\n",
       "model                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             llama-2-7b-chat.ggmlv3.q2_K.bin  \n",
       "prompt                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "\\n    OBJECTIVE:\\n    You are a customer support representative for a startup called Hegel AI.\\n    Answer the following customer question:\\n    Do you offer refunds?\\n    \\n    RESPONSE:\\n                                                                                                                                                                [ Yes, at Hegel AI we understand that sometimes our customers may need to return or cancel their orders. We do indeed offer refunds on certain products. The policy for refunds is available on our website under the \"Returns and Refunds\" section. ]                                                                                                                                                                                                                                                                                                                \n",
       "\\n    OBJECTIVE:\\n    You are a sales development representative for a startup called Hegel AI.\\n    Your startup builds developer tools for large language models.\\n    Draft a short sales email, 50 words or less, asking a prospect for 15 minutes\\n    of their time to chat about how they're using large language models.\\n    \\n    RESPONSE:\\n      [\\n    Subject: Quick Chat on Large Language Models?\\n    \\n    Hi [Prospect Name],\\n    Hope this finds you well! I'm [Your Name], a sales development \\n     representative from Hegel AI, an innovative startup developing \\n     developer tools for large language models. \\n     We have developed cutting-edge technologies to aid in the \\n     improvement and optimization of these models.\\n     \\n       Our products can enhance the efficiency and quality of your work.\\n        I would love to arrange a brief discussion with you to discuss how ]  \n",
       "Who was the first president?                                                                                                                                                                                                                                                                                                                                 NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harness.visualize(\"response(s)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
