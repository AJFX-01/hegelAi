{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation Experiment Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet --force-reinstall prompttools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports and API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll import the relevant `prompttools` modules to setup our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompttools.experiment import ChromaDBExperiment, OpenAICompletionExperiment\n",
    "from prompttools.harness import RetrievalAugmentedGenerationExperimentationHarness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using OpenAI's LLM in this example. You can set up your API key here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"  # Put your key here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data for ChromaDB Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main steps in Retrieval Augmented Generation. We will start with the retrieval step.\n",
    "\n",
    "First, we will setup a vector database experiment. We will insert documents the DB with different embedding functions (vectorizer), and query the results.\n",
    "\n",
    "For this example, we will use ChromaDB, but you use other vector databases as well.\n",
    "\n",
    "For detailed explanation about each step, have a look at the ChromaDB example notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  ) < LooseVersion(\"1.15\"):\n",
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/tensorflow/python/debug/cli/debugger_cli_common.py:19: DeprecationWarning: module 'sre_constants' is deprecated\n",
      "  import sre_constants\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "\n",
    "emb_fns = [\n",
    "    embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"paraphrase-MiniLM-L3-v2\"),\n",
    "    embedding_functions.DefaultEmbeddingFunction(),\n",
    "]  # default is \"all-MiniLM-L6-v2\"\n",
    "emb_fns_names = [\"paraphrase-MiniLM-L3-v2\", \"default\"]\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "# You can also create and use `chromadb.PersistentClient` or `chromadb.HttpClient`\n",
    "TEST_COLLECTION_NAME = \"TEMPORARY_COLLECTION\"\n",
    "try:\n",
    "    chroma_client.delete_collection(TEST_COLLECTION_NAME)\n",
    "except Exception:\n",
    "    pass\n",
    "collection_name = TEST_COLLECTION_NAME\n",
    "\n",
    "use_existing_collection = False  # Specify that we want to create a collection during the experiment\n",
    "\n",
    "# Documents that will be added into the database\n",
    "add_to_collection_params = {\n",
    "    \"documents\": [\"This is a document\", \"This is another document\", \"This is the document.\"],\n",
    "    \"metadatas\": [{\"source\": \"my_source\"}, {\"source\": \"my_source\"}, {\"source\": \"my_source\"}],\n",
    "    \"ids\": [\"id1\", \"id2\", \"id3\"],\n",
    "}\n",
    "\n",
    "# Our test queries\n",
    "query_collection_params = {\"query_texts\": [\"This is a another query document\"]} #[\"This is a query document\", \"This is a another query document\"]}\n",
    "\n",
    "\n",
    "# Set up the experiment\n",
    "vdb_experiment = ChromaDBExperiment(\n",
    "    chroma_client,\n",
    "    collection_name,\n",
    "    use_existing_collection,\n",
    "    query_collection_params,\n",
    "    emb_fns,\n",
    "    emb_fns_names,\n",
    "    add_to_collection_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the results and see what documents have been fetched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n",
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/chromadb/utils/read_write_lock.py:29: DeprecationWarning: notifyAll() is deprecated, use notify_all() instead\n",
      "  self._read_ready.notifyAll()\n",
      "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_fn</th>\n",
       "      <th>top doc ids</th>\n",
       "      <th>distances</th>\n",
       "      <th>documents</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paraphrase-MiniLM-L3-v2</td>\n",
       "      <td>[id2, id3, id1]</td>\n",
       "      <td>[13.375584602355957, 16.815608978271484, 16.913410186767578]</td>\n",
       "      <td>[This is another document, This is the document., This is a document]</td>\n",
       "      <td>0.00923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>default</td>\n",
       "      <td>[id2, id1, id3]</td>\n",
       "      <td>[0.7673601508140564, 0.8709302544593811, 0.9072309732437134]</td>\n",
       "      <td>[This is another document, This is a document, This is the document.]</td>\n",
       "      <td>0.02145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  embed_fn      top doc ids  \\\n",
       "0  paraphrase-MiniLM-L3-v2  [id2, id3, id1]   \n",
       "1  default                  [id2, id1, id3]   \n",
       "\n",
       "                                                      distances  \\\n",
       "0  [13.375584602355957, 16.815608978271484, 16.913410186767578]   \n",
       "1  [0.7673601508140564, 0.8709302544593811, 0.9072309732437134]   \n",
       "\n",
       "                                                               documents  \\\n",
       "0  [This is another document, This is the document., This is a document]   \n",
       "1  [This is another document, This is a document, This is the document.]   \n",
       "\n",
       "   latency  \n",
       "0  0.00923  \n",
       "1  0.02145  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vdb_experiment.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup up Retrieval Augmented Generation Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up your vector database experiment, we can set up the LLM experiment that will consume the documents retrieved from the vector DB. We need:\n",
    "\n",
    "1. LLM experiment (we will use `OpenAICompletionExperiment` here, but you can use something else as well)\n",
    "2. LLM arguments (this will be passed into the LLM experiment)\n",
    "3. A function to extract documents from the resuls of the vector DB experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the arguments we will use for our LLM experiment `OpenAICompletionExperiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"babbage-002\"]\n",
    "prompts = [\"What happened on 01/01/2025?\", \"Who is the 50th president?\"]\n",
    "temperatures = [0.0, 1.0]\n",
    "# You can add more parameters that you'd like to test here.\n",
    "\n",
    "llm_arguments = {\"model\": models, \"prompt\": prompts, \"temperature\": temperatures}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function extracts the list of documents from each row of the vector DB experiment result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_doc_from_row(row: 'pandas.core.series.Series'):\n",
    "    return row['documents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass in everything into the RAG experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_experiment = RetrievalAugmentedGenerationExperimentationHarness(\n",
    "    vector_db_experiment = vdb_experiment,\n",
    "    llm_experiment_cls = OpenAICompletionExperiment,\n",
    "    llm_arguments = llm_arguments,\n",
    "    extract_document_fn = _extract_doc_from_row,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n",
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/chromadb/utils/read_write_lock.py:29: DeprecationWarning: notifyAll() is deprecated, use notify_all() instead\n",
      "  self._read_ready.notifyAll()\n",
      "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>temperature</th>\n",
       "      <th>response</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nGiven these documents:\\nThis is another document\\nThis is the document.\\nThis is a document\\n\\nWhat happened on 01/01/2025?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\nThis is a document\\nThis is a document\\nThis is a document\\n</td>\n",
       "      <td>0.619368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nGiven these documents:\\nThis is another document\\nThis is the document.\\nThis is a document\\n\\nWhat happened on 01/01/2025?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(What everybody in the world thought about the year 2019 in theis</td>\n",
       "      <td>0.243747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nGiven these documents:\\nThis is another document\\nThis is the document.\\nThis is a document\\n\\nWho is the 50th president?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\nA. George Washington\\nB. Abraham Lincoln\\nC. John F.</td>\n",
       "      <td>0.498184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nGiven these documents:\\nThis is another document\\nThis is the document.\\nThis is a document\\n\\nWho is the 50th president?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>And how do you know? You don't. The problem doesn't lie in</td>\n",
       "      <td>0.228347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nGiven these documents:\\nThis is another document\\nThis is a document\\nThis is the document.\\n\\nWhat happened on 01/01/2025?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\nThis is the document\\nThis is another document\\nThis is a document\\n</td>\n",
       "      <td>0.590188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nGiven these documents:\\nThis is another document\\nThis is a document\\nThis is the document.\\n\\nWhat happened on 01/01/2025?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>There are N similar days. You can use the cloud function to calculate the date</td>\n",
       "      <td>1.993902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\nGiven these documents:\\nThis is another document\\nThis is a document\\nThis is the document.\\n\\nWho is the 50th president?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\nA. George Washington\\nB. Abraham Lincoln\\nC. John F.</td>\n",
       "      <td>1.901117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\nGiven these documents:\\nThis is another document\\nThis is a document\\nThis is the document.\\n\\nWho is the 50th president?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Is he black, white or something else?\\n\\nFormat answer using the standard Scien</td>\n",
       "      <td>0.612549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          prompt  \\\n",
       "0  \\nGiven these documents:\\nThis is another document\\nThis is the document.\\nThis is a document\\n\\nWhat happened on 01/01/2025?   \n",
       "1  \\nGiven these documents:\\nThis is another document\\nThis is the document.\\nThis is a document\\n\\nWhat happened on 01/01/2025?   \n",
       "2  \\nGiven these documents:\\nThis is another document\\nThis is the document.\\nThis is a document\\n\\nWho is the 50th president?     \n",
       "3  \\nGiven these documents:\\nThis is another document\\nThis is the document.\\nThis is a document\\n\\nWho is the 50th president?     \n",
       "4  \\nGiven these documents:\\nThis is another document\\nThis is a document\\nThis is the document.\\n\\nWhat happened on 01/01/2025?   \n",
       "5  \\nGiven these documents:\\nThis is another document\\nThis is a document\\nThis is the document.\\n\\nWhat happened on 01/01/2025?   \n",
       "6  \\nGiven these documents:\\nThis is another document\\nThis is a document\\nThis is the document.\\n\\nWho is the 50th president?     \n",
       "7  \\nGiven these documents:\\nThis is another document\\nThis is a document\\nThis is the document.\\n\\nWho is the 50th president?     \n",
       "\n",
       "   temperature  \\\n",
       "0  0.0           \n",
       "1  1.0           \n",
       "2  0.0           \n",
       "3  1.0           \n",
       "4  0.0           \n",
       "5  1.0           \n",
       "6  0.0           \n",
       "7  1.0           \n",
       "\n",
       "                                                                           response  \\\n",
       "0   \\nThis is a document\\nThis is a document\\nThis is a document\\n                    \n",
       "1   (What everybody in the world thought about the year 2019 in theis                 \n",
       "2   \\nA. George Washington\\nB. Abraham Lincoln\\nC. John F.                            \n",
       "3   And how do you know? You don't. The problem doesn't lie in                        \n",
       "4   \\nThis is the document\\nThis is another document\\nThis is a document\\n            \n",
       "5   There are N similar days. You can use the cloud function to calculate the date    \n",
       "6   \\nA. George Washington\\nB. Abraham Lincoln\\nC. John F.                            \n",
       "7   Is he black, white or something else?\\n\\nFormat answer using the standard Scien   \n",
       "\n",
       "    latency  \n",
       "0  0.619368  \n",
       "1  0.243747  \n",
       "2  0.498184  \n",
       "3  0.228347  \n",
       "4  0.590188  \n",
       "5  1.993902  \n",
       "6  1.901117  \n",
       "7  0.612549  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rag_experiment.run()\n",
    "rag_experiment.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
